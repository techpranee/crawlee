# LinkedIn Lead Generation - System Architecture

## ðŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User / Frontend                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP API
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Express REST API (Port 3011)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Campaigns   â”‚  â”‚  Strategies  â”‚  â”‚    Admin     â”‚          â”‚
â”‚  â”‚   Routes     â”‚  â”‚   Routes     â”‚  â”‚   Routes     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                  â”‚                  â”‚                   â”‚
â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚         â”‚  â”‚                                                      â”‚
â”‚         â–¼  â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚         Tenant Middleware (Multi-tenant Auth)        â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Agenda Job Queue (MongoDB)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Job Types:                                           â”‚       â”‚
â”‚  â”‚  â€¢ scrape:crawl   - Main scraping job                â”‚       â”‚
â”‚  â”‚  â€¢ enrich:contacts - Email enrichment                â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Crawl Services Layer                        â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Rate Limiter (rateLimiter.ts)              â”‚   â”‚
â”‚  â”‚  â€¢ 10-min delays  â€¢ Exponential backoff                 â”‚   â”‚
â”‚  â”‚  â€¢ Per-domain tracking  â€¢ Extended backoff (2hr)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            Proxy Rotator (proxyRotator.ts)              â”‚   â”‚
â”‚  â”‚  â€¢ Random/RR rotation  â€¢ Health tracking                â”‚   â”‚
â”‚  â”‚  â€¢ Auto-cooldown  â€¢ Credential masking                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                     â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚              â–¼                           â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   Firecrawl API    â”‚      â”‚   Playwright       â”‚            â”‚
â”‚  â”‚   (External SaaS)  â”‚      â”‚   (Local Browser)  â”‚            â”‚
â”‚  â”‚  â€¢ 3 retry attemptsâ”‚      â”‚  â€¢ Cookie auth     â”‚            â”‚
â”‚  â”‚  â€¢ Exponential b/o â”‚      â”‚  â€¢ Stealth mode    â”‚            â”‚
â”‚  â”‚  â€¢ 60s timeout     â”‚      â”‚  â€¢ Network idle    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚              â”‚                           â”‚                       â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Extractors (extractors.ts)                 â”‚   â”‚
â”‚  â”‚  â€¢ CSS selector-based extraction                        â”‚   â”‚
â”‚  â”‚  â€¢ Data normalization                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MongoDB Atlas (Data Layer)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Campaigns   â”‚  â”‚  Companies   â”‚  â”‚   Contacts   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Tenants    â”‚  â”‚    Tasks     â”‚  â”‚  Strategies  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Export / Output Layer                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  CSV Exporter (contactExporter.ts)                     â”‚     â”‚
â”‚  â”‚  â€¢ Streaming export  â€¢ Custom field mapping            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“Š Data Flow: Campaign Creation to CSV Export

### Step-by-Step Flow

```
1. User creates campaign via POST /api/campaigns
   â†“
2. Campaign document saved to MongoDB
   â†“
3. Agenda job "scrape:crawl" scheduled
   â†“
4. Job handler (scrapeCrawl.ts) picks up job
   â†“
5. Rate Limiter checks: "Can I make request now?"
   â€¢ If too soon: Wait (10+ minutes)
   â€¢ If OK: Proceed
   â†“
6. Proxy Rotator selects next healthy proxy
   â†“
7. Try Firecrawl first (LinkedIn URLs only):
   â€¢ Attempt 1 â†’ Wait 1s â†’ Attempt 2 â†’ Wait 2s â†’ Attempt 3
   â€¢ If all fail: Fall back to Playwright
   â†“
8. Playwright crawler starts:
   â€¢ Launch Chrome with stealth mode
   â€¢ Add LinkedIn cookies to browser context
   â€¢ Apply HTTP headers
   â€¢ Navigate to seed URL
   â†“
9. Wait for content:
   â€¢ Wait for network idle (no requests for 500ms)
   â€¢ Wait for specific selectors (LinkedIn feed)
   â€¢ Scroll page to trigger lazy loading
   â€¢ Additional 2-5 second delay
   â†“
10. Extract data using CSS selectors:
    â€¢ name: .entity-result__title-text
    â€¢ title: .entity-result__primary-subtitle
    â€¢ company: .entity-result__secondary-subtitle
    â€¢ etc.
   â†“
11. Normalize extracted data (normalize.ts):
    â€¢ Clean whitespace
    â€¢ Deduplicate
    â€¢ Create Company and Contact documents
   â†“
12. Save to MongoDB:
    â€¢ Campaign.status = 'completed'
    â€¢ Company documents created/updated
    â€¢ Contact documents created
   â†“
13. User exports via GET /api/campaigns/{id}/export
   â†“
14. CSV streamed back to user
```

## ðŸ” Rate Limiting Logic

### Decision Tree

```
Request arrives for linkedin.com
â”‚
â”œâ”€â†’ Check if domain is blocked (in extended backoff)
â”‚   â€¢ Yes â†’ Throw error "Wait X minutes"
â”‚   â€¢ No â†’ Continue
â”‚
â”œâ”€â†’ Calculate requests in last 60 minutes
â”‚   â€¢ If >= 10 â†’ Wait until oldest request expires
â”‚   â€¢ If < 10 â†’ Continue
â”‚
â”œâ”€â†’ Calculate time since last request
â”‚   â€¢ If < 10 minutes â†’ Wait remaining time
â”‚   â€¢ If >= 10 minutes â†’ Continue
â”‚
â”œâ”€â†’ Apply exponential backoff if consecutive 429s
â”‚   â€¢ 0 failures: 10 min delay
â”‚   â€¢ 1 failure: 20 min delay
â”‚   â€¢ 2 failures: 40 min delay
â”‚   â€¢ 3+ failures: Enter 2-hour extended backoff
â”‚
â””â”€â†’ Add random jitter (Â±5 minutes)
    â””â”€â†’ Wait calculated delay
        â””â”€â†’ Make request
```

### After Request

```
Response received
â”‚
â”œâ”€â†’ HTTP 200-299 (Success)
â”‚   â€¢ Record success
â”‚   â€¢ Reset consecutive failures to 0
â”‚   â€¢ Clear backoff period
â”‚
â”œâ”€â†’ HTTP 429 (Rate Limited)
â”‚   â€¢ Increment consecutive failures
â”‚   â€¢ If >= 3: Enter extended backoff (2 hours)
â”‚   â€¢ Record rate limit event
â”‚
â””â”€â†’ HTTP 400-599 (Other Error)
    â€¢ Record error
    â€¢ Do NOT increment consecutive failures
    â€¢ (Not a rate limit issue)
```

## ðŸ”„ Proxy Rotation Logic

### Selection Algorithm

```
Get next proxy request
â”‚
â”œâ”€â†’ Filter to healthy proxies only
â”‚   â€¢ Healthy: consecutiveFailures < 3
â”‚   â€¢ Unhealthy: In 30-min cooldown period
â”‚
â”œâ”€â†’ If no healthy proxies available
â”‚   â€¢ Check if any in cooldown period expired
â”‚   â€¢ If yes: Mark as healthy, use it
â”‚   â€¢ If no: Use direct connection (no proxy)
â”‚
â”œâ”€â†’ Apply rotation strategy:
â”‚   â€¢ Random: Pick random healthy proxy
â”‚   â€¢ Round-robin: Cycle through in order
â”‚
â””â”€â†’ Return selected proxy URL
```

### Health Tracking

```
Proxy request completes
â”‚
â”œâ”€â†’ Success (HTTP 200-299)
â”‚   â€¢ Increment successCount
â”‚   â€¢ Reset consecutiveFailures = 0
â”‚   â€¢ Mark as healthy
â”‚
â””â”€â†’ Failure (Network error, timeout, HTTP 5xx)
    â€¢ Increment failureCount
    â€¢ Increment consecutiveFailures
    â”‚
    â””â”€â†’ If consecutiveFailures >= 3
        â€¢ Mark as unhealthy
        â€¢ Start 30-minute cooldown
        â€¢ Log warning
```

## ðŸ§© Key Components

### Rate Limiter (`rateLimiter.ts`)

**Purpose**: Prevent HTTP 429 errors by enforcing delays

**Configuration** (hardcoded for LinkedIn):
```typescript
{
  minDelayMs: 10 * 60 * 1000,      // 10 minutes
  maxDelayMs: 60 * 60 * 1000,      // 60 minutes
  jitterMs: 5 * 60 * 1000,         // Â±5 minutes
  backoffMultiplier: 2,            // Double on each 429
  maxConsecutiveRateLimits: 3,    // Threshold for extended backoff
  extendedBackoffMs: 2 * 60 * 60 * 1000, // 2 hours
  requestWindowMs: 60 * 60 * 1000, // 1 hour
  maxRequestsPerWindow: 10,        // Max 10/hour
}
```

**Methods**:
- `waitBeforeRequest(url)` - Enforces delay before making request
- `recordSuccess(url)` - Records successful request
- `recordRateLimit(url)` - Records HTTP 429 error
- `recordError(url)` - Records other errors
- `getStats(url)` - Returns current state for monitoring
- `reset(url)` - Resets state (admin operation)

### Proxy Rotator (`proxyRotator.ts`)

**Purpose**: Distribute requests across multiple residential IPs

**Configuration** (from env vars):
```bash
PROXY_URLS=http://proxy1:8080,http://proxy2:8080
PROXY_ROTATION=random  # or 'round-robin'
```

**State per proxy**:
```typescript
{
  url: string;
  successCount: number;
  failureCount: number;
  consecutiveFailures: number;
  lastUsed: number;
  lastFailure: number | null;
  isHealthy: boolean;
}
```

**Methods**:
- `getNextProxy()` - Returns next proxy based on strategy
- `recordSuccess(proxyUrl)` - Records successful request
- `recordFailure(proxyUrl, reason?)` - Records failure
- `getStats()` - Returns health stats for all proxies
- `reset(proxyUrl?)` - Resets one or all proxies

### Crawlers (`crawlers.ts`)

**Purpose**: Execute scraping with Playwright or Cheerio

**Integration points**:
```typescript
// Before request
await rateLimiter.waitBeforeRequest(url);
const proxyUrl = proxyRotator.getNextProxy();

// Configure crawler
new PlaywrightCrawler({
  proxyConfiguration: new ProxyConfiguration({ proxyUrls: [proxyUrl] }),
  // ... other config
});

// After successful request
rateLimiter.recordSuccess(url);
proxyRotator.recordSuccess(proxyUrl);

// On HTTP 429
rateLimiter.recordRateLimit(url);

// On error
rateLimiter.recordError(url);
proxyRotator.recordFailure(proxyUrl, reason);
```

### Admin Routes (`routes/admin.ts`)

**Purpose**: Monitor and manage scraping infrastructure

**Endpoints**:

1. **GET /api/admin/rate-limiter/stats**
   ```bash
   curl "http://localhost:3011/api/admin/rate-limiter/stats?url=https://linkedin.com"
   ```
   Returns: Current delay requirements, backoff status, request counts

2. **POST /api/admin/rate-limiter/reset**
   ```bash
   curl -X POST http://localhost:3011/api/admin/rate-limiter/reset \
     -d '{"url": "https://linkedin.com"}'
   ```
   Resets rate limiter state for domain

3. **GET /api/admin/proxies/stats**
   ```bash
   curl http://localhost:3011/api/admin/proxies/stats
   ```
   Returns: Proxy health, success/failure counts, last used times

4. **POST /api/admin/proxies/reset**
   ```bash
   curl -X POST http://localhost:3011/api/admin/proxies/reset \
     -d '{"proxyUrl": "http://proxy1:8080"}'
   ```
   Resets proxy health status

## ðŸŽ¯ Production Deployment

### Infrastructure Requirements

1. **Application Server**
   - Node.js 18+
   - 2GB RAM minimum (4GB recommended)
   - 10GB disk space for storage
   - Ubuntu 20.04+ or similar

2. **MongoDB Atlas**
   - M10 cluster or higher (production)
   - Automated backups enabled
   - Connection from app server whitelisted

3. **Residential Proxies**
   - Minimum 3-5 rotating IPs
   - Residential (not datacenter)
   - Providers: BrightData, Oxylabs, Smartproxy
   - Budget: $50-150/month

4. **LinkedIn Cookies**
   - Valid authenticated session
   - Refreshed every 7-14 days
   - Stored securely in MongoDB (tenant.linkedinCookie)

### Deployment Checklist

- [ ] Server provisioned with Node.js
- [ ] MongoDB Atlas cluster created
- [ ] Proxies configured in PROXY_URLS
- [ ] LinkedIn cookies added to tenant
- [ ] Environment variables set
- [ ] Backend started with pm2 or similar
- [ ] Health check endpoint responding
- [ ] Rate limiter stats verified (600s delay)
- [ ] Proxy stats verified (all healthy)
- [ ] Test campaign created
- [ ] First lead exported to CSV

### Monitoring

**Set up alerts for**:
- HTTP 429 rate > 10%
- All proxies unhealthy
- Campaign completion failures > 25%
- MongoDB connection errors
- Disk space < 20%

**Log aggregation**:
- Send logs to CloudWatch, Datadog, or similar
- Set up dashboard with key metrics:
  - Requests per hour
  - Success rate
  - Average delay time
  - Proxy health status

## ðŸ”’ Security Considerations

1. **API Keys**
   - Use strong random keys (32+ chars)
   - Rotate regularly (every 90 days)
   - Store in environment variables, not code

2. **LinkedIn Cookies**
   - Encrypt in MongoDB (at-rest encryption)
   - Use separate cookies per tenant
   - Rotate cookies if suspicious activity

3. **Proxy Credentials**
   - Never log full credentials
   - Mask in logs (rateLimiter.ts does this)
   - Use HTTPS proxies when possible

4. **Rate Limiting**
   - Do NOT reduce delays below 10 minutes
   - Respect LinkedIn's TOS
   - Monitor for pattern detection

## ðŸ“š Related Documentation

- **Production Guide**: `LINKEDIN_PRODUCTION.md` - Complete setup guide
- **Quick Reference**: `QUICK_REFERENCE.md` - Common commands
- **Before/After**: `BEFORE_AFTER.md` - What changed and why
- **Implementation Summary**: `IMPLEMENTATION_SUMMARY.md` - Technical details

---

**Last Updated**: October 2025
**Version**: 1.0.0
